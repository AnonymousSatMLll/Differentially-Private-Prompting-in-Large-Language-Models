Differentially-Private Prompting in Large Language Models (DualTune-GhostDP)
Overview

With growing concerns about data privacy and confidentiality, privacy-preserving techniques are becoming essential for data-driven applications, especially Large Language Models (LLMs). LLMs excel at in-context learning and are widely used in real-world applications, but they often rely on sensitive private data, making them vulnerable to data leakage and privacy breaches.

Our project proposes DualTune-GhostDP, a two-phase fine-tuning framework for LLMs that balances privacy and utility. By using Ghost Clipping and controlling privacy with the EW Advanced Accountant instead of traditional privacy accountants, our model maintains strong Differential Privacy (DP) guarantees while achieving high performance and improved computational efficiency.
